{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- years being used for evaluation\n",
    "Years = '2004'\n",
    "\n",
    "# -- spatial key being used for calculation\n",
    "SpatialKey = 'ZIPCODE'\n",
    "\n",
    "# -- use Fiscal or Calendar year\n",
    "UseFiscalYear = True\n",
    "\n",
    "# -- input path\n",
    "if UseFiscalYear:\n",
    "    InputPath = '../../shapeData/Dataframes_Fiscal/'\n",
    "else:\n",
    "    InputPath = '../../shapeData/Dataframes/'\n",
    "\n",
    "# -- Census Park Breakdown input file\n",
    "CensusParkInputFile = '../../shapeData/Tables/Park_Area_Census_Tract.xlsx'\n",
    "\n",
    "# -- output path\n",
    "OutputPath = '../../shapeData/Tables/'\n",
    "WriteOutputPath = '../../shapeData/Tables/ParkQualityScores/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 2013_Inspections.csv...\n",
      "reading 2014_Inspections.csv...\n",
      "reading 2015_Inspections.csv...\n"
     ]
    }
   ],
   "source": [
    "# -- read the park quality file on a year basis \n",
    "\n",
    "# -- for each year of analysis, merge files into 1\n",
    "\n",
    "# -- clear df first so block can be rerun in notebook\n",
    "yearDF = pd.DataFrame({})\n",
    "for Year in Years.split(','):\n",
    "    print \"reading %s_Inspections.csv...\" % (Year)\n",
    "    df = pd.read_csv(InputPath + '%s_Inspections.csv' % (Year), index_col=0, sep='\\t')\n",
    "    try:\n",
    "        yearDF = yearDF.append(df, ignore_index=True)\n",
    "    except:\n",
    "        yearDF = df\n",
    "\n",
    "# -- append resorts columns.  reinstate column order\n",
    "yearDF = yearDF.reindex_axis(df.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- read the park listing breakdowns by census tract\n",
    "if SpatialKey == 'GEOID':\n",
    "    print \"reading census park info file...\"\n",
    "    censusParkDF = pd.read_excel(CensusParkInputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Amenity Files\n"
     ]
    }
   ],
   "source": [
    "# -- read the Amenity files \n",
    "print \"reading Amenity Files\"\n",
    "amenityFlagFilter = pd.read_excel(OutputPath + \"PIP_Inventory_CUSP.xlsx\")\n",
    "amenityCompleteList = pd.read_excel(OutputPath + \"PIP_Inventory_Client.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- categories\n",
    "categories = [u'Athletic Fields', u'Benches',\n",
    "       u'Fences', u'Glass', u'Graffiti', u'Horticultural Areas', u'Ice',\n",
    "       u'Lawns', u'Litter', u'Paved Surfaces', u'Play Equipment',\n",
    "       u'Safety Surface', u'Sidewalks', u'Trails', u'Trees', u'Water Bodies',\n",
    "       u'Weeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- calculate inspection scores [ratio]\n",
    "yearDF['Ratings Ratio'] = 1 - yearDF[categories].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- build attribute list to capture from inspection reports.  \n",
    "# --   If Spatial included, grab it.  If not, its GEOID which is in a different file\n",
    "yearDFAttr = ['Prop ID', 'PID_base', 'Category']\n",
    "if SpatialKey in yearDF.columns:\n",
    "    yearDFAttr.append(SpatialKey)\n",
    "\n",
    "# -- seed final park stats DF\n",
    "byParkID = yearDF[yearDFAttr].groupby(['Prop ID'], as_index = False)\n",
    "parkStats = byParkID.first()\n",
    "\n",
    "\n",
    "# -- average Park Score and Acres\n",
    "byPark = yearDF.groupby(['Prop ID'], as_index = False)\n",
    "parkAvgScore = byPark['Ratings Ratio','Adjusted Acres'].mean()\n",
    "parkAvgScore.rename(columns={'Ratings Ratio':'Score'}, inplace=True)\n",
    "parkAvgScore.rename(columns={'Adjusted Acres':'Acres'}, inplace=True)\n",
    "parkStats = pd.merge(parkStats, parkAvgScore, on='Prop ID', how='left')\n",
    "\n",
    "# -- Utilize new park table which has parks broken up by census tracts if used!\n",
    "if SpatialKey == 'GEOID':\n",
    "    parkStats = pd.merge(censusParkDF[['Prop ID', 'GEOID', 'Fractional Acres']], parkStats, on = 'Prop ID', how = 'left')\n",
    "    \n",
    "    # -- Replace acerage with census breakup acreage\n",
    "    parkStats['Acres'] = parkStats['Fractional Acres']\n",
    "    parkStats.drop('Fractional Acres', axis=1, inplace=True)\n",
    "\n",
    "# -- calculate weighted Score for park\n",
    "parkStats['Score * Acres'] = parkStats['Score'] * parkStats['Acres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- Build Amenity List Mask\n",
    "AmenitiesTypesToInclude = amenityFlagFilter[amenityFlagFilter['Include'] == 1].set_index(['Feature', 'Type', 'Category'])\n",
    "\n",
    "# -- Apply mask to get Park Amenities to sum\n",
    "amenityCompleteList.set_index(['Feature', 'Type', 'Category'], inplace=True)\n",
    "ParkAmenitiesToInclude = amenityCompleteList.loc[AmenitiesTypesToInclude.index].reset_index()\n",
    "amenityCompleteList.reset_index(inplace=True)\n",
    "\n",
    "# -- Sum per park\n",
    "byPark = amenityCompleteList.groupby('Prop ID').size()\n",
    "\n",
    "# -- Append quantity of amenities to Park reports\n",
    "parksWithAmenities = parkStats.set_index('Prop ID')\n",
    "parksWithAmenities['m'] = byPark\n",
    "parksWithAmenities.reset_index(inplace = True)\n",
    "\n",
    "# -- Replace Nulls with 0\n",
    "parksWithAmenities['m'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- seed district_category stats DF to calculate the mean Ameneties in each zipcode\n",
    "byCategory = parksWithAmenities.groupby([SpatialKey] + ['Category'], as_index = False)\n",
    "\n",
    "# -- calculate average amneties in each zipcode <m>\n",
    "catAmenity = byCategory['m'].mean()\n",
    "catAmenity.rename(columns={'m':'<m>'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Join the amenity average table to the orginal park info table to calculate the equation\n",
    "amenityEquationDataframe = pd.merge(parksWithAmenities, catAmenity, on=[SpatialKey,'Category'], how='left')\n",
    "\n",
    "# -- Apply Equation\n",
    "amenityEquationDataframe['m/<m>'] = amenityEquationDataframe['m']/amenityEquationDataframe['<m>']\n",
    "amenityEquationDataframe['m/<m>'].replace(np.inf, 0)\n",
    "amenityEquationDataframe['m/<m>'].fillna(0, inplace=True)\n",
    "amenityEquationDataframe['1 + m/<m>'] = 1+(amenityEquationDataframe['m/<m>'])\n",
    "amenityEquationDataframe['W'] = amenityEquationDataframe['Acres']*amenityEquationDataframe['1 + m/<m>']\n",
    "amenityEquationDataframe['W*Q'] = amenityEquationDataframe['W']*amenityEquationDataframe['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- seed district_category stats DF\n",
    "byCategory = amenityEquationDataframe.groupby([SpatialKey] + ['Category'], as_index = False)\n",
    "categoryStats = byCategory.first()[[SpatialKey] + ['Category']]\n",
    "\n",
    "# -- sum WQ and W per category\n",
    "catSums = byCategory['Acres', 'Score', 'Score * Acres','W*Q', 'W'].sum()\n",
    "# catSums.rename(columns={'Weighted Score':'Score'}, inplace=True)\n",
    "categoryStats = pd.merge(categoryStats, catSums, on=[SpatialKey] + ['Category'], how='left')\n",
    "\n",
    "# -- count parks per category\n",
    "catCounts = byCategory.size().reset_index().rename(columns={0:'Counts'})\n",
    "categoryStats = pd.merge(categoryStats, catCounts, on=[SpatialKey] + ['Category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- group by zipcode and category\n",
    "bySpatialKey = categoryStats.groupby(SpatialKey, as_index = False)\n",
    "SpatialKeySums = bySpatialKey.sum()[[SpatialKey] + ['Counts']]\n",
    "\n",
    "categoryStats = pd.merge(categoryStats, SpatialKeySums, on=SpatialKey, how = 'left', suffixes = ['_Cat', '_%s' % SpatialKey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- calculate weighted scores for SpatialKey\n",
    "\n",
    "# -- Normalized score\n",
    "categoryStats['Non-Weighted Score'] = categoryStats['Score'] / categoryStats['Counts_Cat']\n",
    "categoryStats['Naive Normalized Score'] = categoryStats['Non-Weighted Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_%s' % SpatialKey])\n",
    "\n",
    "# -- Area Normalized Score\n",
    "categoryStats['Weighted Score'] = categoryStats['Score * Acres'] / categoryStats['Acres']\n",
    "categoryStats['Area Normalized Score'] = categoryStats['Weighted Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_%s' % SpatialKey])\n",
    "\n",
    "# -- Area and Amenities weighted score\n",
    "categoryStats['Equation Score'] = categoryStats['W*Q'] / categoryStats['W']\n",
    "categoryStats['Amenities & Area Normalized Score'] = categoryStats['Equation Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_%s' % SpatialKey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- sum Scores per Zipcode\n",
    "bySpatialKey = categoryStats.groupby(SpatialKey)\n",
    "SpatialStats = bySpatialKey \\\n",
    "                    .sum() \\\n",
    "                    .reset_index() \\\n",
    "                    [[SpatialKey] + ['Naive Normalized Score'] + ['Area Normalized Score'] + ['Amenities & Area Normalized Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- floor scores at 0 just in case U/S overtake ratios\n",
    "SpatialStats.loc[SpatialStats['Amenities & Area Normalized Score'] < 0, 'Amenities & Area Normalized Score'] = 0\n",
    "SpatialStats.loc[SpatialStats['Area Normalized Score'] < 0, 'Area Normalized Score'] = 0\n",
    "SpatialStats.loc[SpatialStats['Naive Normalized Score'] < 0, 'Naive Normalized Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Write to csv\n",
    "now = datetime.now()\n",
    "if UseFiscalYear:\n",
    "    YearType = 'FiscalYr'\n",
    "else:\n",
    "    YearType = 'CalendarYr'\n",
    "SpatialStats.to_csv(WriteOutputPath + 'ParkQuality_%s_%s_%s_%s.csv' % (SpatialKey, Years.replace(',','&'), YearType, now.strftime('%m-%d-%Y')), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
