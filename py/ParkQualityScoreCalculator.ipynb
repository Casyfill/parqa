{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- years being used for evaluation\n",
    "Years = '2014'\n",
    "\n",
    "# -- spatial key being used for calculation\n",
    "SpatialKey = 'ZIPCODE'\n",
    "\n",
    "# -- input path\n",
    "InputPath = '../../shapeData/Dataframes/'\n",
    "\n",
    "# -- Census Park Breakdown input file\n",
    "CensusParkInputFile = '../../shapeData/Tables/AllSites_MasterPropID_CT.xlsx'\n",
    "\n",
    "# -- output path\n",
    "OutputPath = '../../shapeData/Tables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- read the park quality file on a year basis \n",
    "try:\n",
    "    yearDF\n",
    "    \n",
    "except: \n",
    "    # -- for each year of analysis, merge files into 1\n",
    "    \n",
    "    # -- clear df first so block can be rerun in notebook\n",
    "    yearDF = pd.DataFrame({})\n",
    "    for Year in Years.split(','):\n",
    "        print \"reading %s_Inspections.csv...\" % (Year)\n",
    "        df = pd.read_csv(InputPath + '%s_Inspections.csv' % (Year), index_col=0, sep='\\t')\n",
    "        try:\n",
    "            yearDF = yearDF.append(df, ignore_index=True)\n",
    "        except:\n",
    "            yearDF = df\n",
    "\n",
    "    # -- append resorts columns.  reinstate column order\n",
    "    yearDF = yearDF.reindex_axis(df.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- read the park listing breakdowns by census tract\n",
    "try:\n",
    "    censusParkDF\n",
    "except:\n",
    "    if SpatialKey == 'GEOID':\n",
    "        print \"reading census park info file...\"\n",
    "        censusParkDF = pd.read_excel(CensusParkInputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- read the Amenity files \n",
    "try:\n",
    "    amenityFlagFilter\n",
    "except:\n",
    "    print \"reading Amenity Files\"\n",
    "    amenityFlagFilter = pd.read_excel(OutputPath + \"PIP_Inventory_CUSP.xlsx\")\n",
    "    amenityCompleteList = pd.read_excel(OutputPath + \"PIP_Inventory_Client.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- categories\n",
    "categories = [u'Athletic Fields', u'Benches',\n",
    "       u'Fences', u'Glass', u'Graffiti', u'Horticultural Areas', u'Ice',\n",
    "       u'Lawns', u'Litter', u'Paved Surfaces', u'Play Equipment',\n",
    "       u'Safety Surface', u'Sidewalks', u'Trails', u'Trees', u'Water Bodies',\n",
    "       u'Weeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- calculate inspection scores [ratio]\n",
    "yearDF['Ratings Ratio'] = 1 - yearDF[categories].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- build attribute list to capture from inspection reports.  \n",
    "# --   If Spatial included, grab it.  If not, its GEOID which is in a different file\n",
    "yearDFAttr = ['Prop ID', 'PID_base', 'Category']\n",
    "if SpatialKey in yearDF.columns:\n",
    "    yearDFAttr.append(SpatialKey)\n",
    "\n",
    "# -- seed final park stats DF\n",
    "byParkID = yearDF[yearDFAttr].groupby(['Prop ID'], as_index = False)\n",
    "parkStats = byParkID.first()\n",
    "\n",
    "\n",
    "# -- average Park Score and Acres\n",
    "byPark = yearDF.groupby(['Prop ID'], as_index = False)\n",
    "parkAvgScore = byPark['Ratings Ratio','Adjusted Acres'].mean()\n",
    "parkAvgScore.rename(columns={'Ratings Ratio':'Score'}, inplace=True)\n",
    "parkAvgScore.rename(columns={'Adjusted Acres':'Acres'}, inplace=True)\n",
    "parkStats = pd.merge(parkStats, parkAvgScore, on='Prop ID', how='left')\n",
    "\n",
    "# -- Utilize new park table which has parks broken up by census tracts if used!\n",
    "if SpatialKey == 'GEOID':\n",
    "    parkStats = pd.merge(censusParkDF[['Prop ID', 'GEOID', 'Fractional Acres']], parkStats, on = 'Prop ID', how = 'left')\n",
    "    \n",
    "    # -- Replace acerage with census breakup acreage\n",
    "    parkStats['Acres'] = parkStats['Fractional Acres']\n",
    "    parkStats.drop('Fractional Acres', axis=1, inplace=True)\n",
    "\n",
    "# -- calculate weighted Score for park\n",
    "parkStats['Score * Acres'] = parkStats['Score'] * parkStats['Acres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- seed district_category stats DF to calculate the mean Ameneties in each zipcode\n",
    "byCategory = parksWithAmenities.groupby([SpatialKey] + ['Category'], as_index = False)\n",
    "\n",
    "# -- calculate average amneties in each zipcode <m>\n",
    "catAmenity = byCategory['m'].mean()\n",
    "catAmenity.rename(columns={'m':'<m>'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Join the amenity average table to the orginal park info table to calculate the equation\n",
    "amenityEquationDataframe = pd.merge(parksWithAmenities, catAmenity, on=[SpatialKey,'Category'], how='left')\n",
    "\n",
    "# -- Apply Equation\n",
    "amenityEquationDataframe['m/<m>'] = amenityEquationDataframe['m']/amenityEquationDataframe['<m>']\n",
    "amenityEquationDataframe['m/<m>'].replace(np.inf, 0)\n",
    "amenityEquationDataframe['m/<m>'].fillna(0, inplace=True)\n",
    "amenityEquationDataframe['1 + m/<m>'] = 1+(amenityEquationDataframe['m/<m>'])\n",
    "amenityEquationDataframe['W'] = amenityEquationDataframe['Acres']*amenityEquationDataframe['1 + m/<m>']\n",
    "amenityEquationDataframe['W*Q'] = amenityEquationDataframe['W']*amenityEquationDataframe['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- seed district_category stats DF\n",
    "byCategory = amenityEquationDataframe.groupby([SpatialKey] + ['Category'], as_index = False)\n",
    "categoryStats = byCategory.first()[[SpatialKey] + ['Category']]\n",
    "\n",
    "# -- sum WQ and W per category\n",
    "catSums = byCategory['Acres', 'Score', 'Score * Acres','W*Q', 'W'].sum()\n",
    "# catSums.rename(columns={'Weighted Score':'Score'}, inplace=True)\n",
    "categoryStats = pd.merge(categoryStats, catSums, on=[SpatialKey] + ['Category'], how='left')\n",
    "\n",
    "# -- count parks per category\n",
    "catCounts = byCategory.size().reset_index().rename(columns={0:'Counts'})\n",
    "categoryStats = pd.merge(categoryStats, catCounts, on=[SpatialKey] + ['Category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- group by zipcode and category\n",
    "bySpatialKey = categoryStats.groupby(SpatialKey, as_index = False)\n",
    "SpatialKeySums = bySpatialKey.sum()[[SpatialKey] + ['Counts']]\n",
    "\n",
    "categoryStats = pd.merge(categoryStats, SpatialKeySums, on=SpatialKey, how = 'left', suffixes = ['_Cat', '_%s' % SpatialKey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- calculate weighted scores for SpatialKey\n",
    "\n",
    "# -- Normalized score\n",
    "categoryStats['Non-Weighted Score'] = categoryStats['Score'] / categoryStats['Counts_Cat']\n",
    "categoryStats['Naive Normalized Score'] = categoryStats['Non-Weighted Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_%s' % SpatialKey])\n",
    "\n",
    "# -- Area Normalized Score\n",
    "categoryStats['Weighted Score'] = categoryStats['Score * Acres'] / categoryStats['Acres']\n",
    "categoryStats['Area Normalized Score'] = categoryStats['Weighted Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_%s' % SpatialKey])\n",
    "\n",
    "# -- Area and Amenities weighted score\n",
    "categoryStats['Equation Score'] = categoryStats['W*Q'] / categoryStats['W']\n",
    "categoryStats['Amenities & Area Normalized Score'] = categoryStats['Equation Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_%s' % SpatialKey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- sum Scores per Zipcode\n",
    "bySpatialKey = categoryStats.groupby(SpatialKey)\n",
    "SpatialStats = bySpatialKey \\\n",
    "                    .sum() \\\n",
    "                    .reset_index() \\\n",
    "                    [[SpatialKey] + ['Naive Normalized Score'] + ['Area Normalized Score'] + ['Amenities & Area Normalized Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- floor scores at 0 just in case U/S overtake ratios\n",
    "SpatialStats.loc[SpatialStats['Amenities & Area Normalized Score'] < 0, 'Amenities & Area Normalized Score'] = 0\n",
    "SpatialStats.loc[SpatialStats['Area Normalized Score'] < 0, 'Area Normalized Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Write to csv\n",
    "now = datetime.now()\n",
    "SpatialStats.to_csv(OutputPath + 'ParkQuality_%s_%s_%s.csv' % (SpatialKey, Years.replace(',','&'), now.strftime('%m-%d-%Y')), sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
