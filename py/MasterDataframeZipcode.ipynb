{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading PIP_InspectionMain.xlsx...\n"
     ]
    }
   ],
   "source": [
    "# -- read the inspection files\n",
    "try:\n",
    "    inspection\n",
    "except:\n",
    "    print(\"reading PIP_InspectionMain.xlsx...\")\n",
    "    in_path = os.path.join('/projects/cusp/10266/0/quality_assessment','PIP')\n",
    "    in_name = os.path.join(in_path,'PIP_InspectionMain.xlsx')\n",
    "    inspection  = pd.read_excel(in_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading PIP_ALLSITES.xlsx...\n"
     ]
    }
   ],
   "source": [
    "# -- get all the ratings information\n",
    "try:\n",
    "    rating\n",
    "except:\n",
    "    print(\"reading PIP_ALLSITES.xlsx...\")\n",
    "    as_path  = os.path.join('/projects/cusp/10266/0/quality_assessment','PIP')\n",
    "    as_name  = os.path.join(as_path,'PIP_FeatureRatings.xlsx')\n",
    "    rating = pd.read_excel(as_name)\n",
    "    \n",
    "    # -- Sustitute numerical values to ratings\n",
    "    rating.loc[rating['Rating'] == 'a', ['Rating']] = 1\n",
    "    rating.loc[rating['Rating'] == 'A', ['Rating']] = 1\n",
    "    rating.loc[rating['Rating'] == 'N', ['Rating']] = np.nan\n",
    "    rating.loc[rating['Rating'] == 'U', ['Rating']] = 0\n",
    "    rating.loc[rating['Rating'] == 'U/S', ['Rating']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading PIP_ALLSITES.xlsx...\n"
     ]
    }
   ],
   "source": [
    "# -- get all the sites information\n",
    "try:\n",
    "    sites\n",
    "except:\n",
    "    print(\"reading PIP_ALLSITES.xlsx...\")\n",
    "    as_path  = os.path.join('/projects/cusp/10266/0/quality_assessment','PIP')\n",
    "    as_name  = os.path.join(as_path,'PIP_ALLSITES.xlsx')\n",
    "    sites = pd.read_excel(as_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Property.shp...\n"
     ]
    }
   ],
   "source": [
    "# -- read in the property files\n",
    "try:\n",
    "    prop\n",
    "except:\n",
    "    print(\"reading Property.shp...\")\n",
    "    pr_path = os.path.join('/scratch/share/gdobler/parqa/output','CUSPExportShps')\n",
    "    pr_name = os.path.join(pr_path,'Property.shp')\n",
    "    prop    = gp.GeoDataFrame.from_file(pr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- pull off only first zip in list (if there are multiple)\n",
    "prop.ZIPCODE = prop.ZIPCODE.apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- Change Rating type to float for calculations\n",
    "rating[['Rating']] = rating[['Rating']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- Create pivot table of inspections.\n",
    "pivotInspect = rating.pivot(index='Inspection ID', columns = 'Feature', values = 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- create the base ID column  MAY HAVE TO BE TWEAKED\n",
    "inspection['PID_base'] = [i.split('-')[0].replace('Z','') \n",
    "                      for i in inspection['Prop ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Remove Greenstreets from sites\n",
    "sites = sites[sites['Category'] != 'Greenstreet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Merge inspection report with sites [Greenstreets are removed from sites]\n",
    "finalDF = pd.merge(sites, inspection, on = 'Prop ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- Drop sites that have inspections\n",
    "finalDF = finalDF[finalDF['Inspection ID'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- Merge frame with pivot table of inspections on Inspection ID\n",
    "finalDF = pd.merge(finalDF, pivotInspect, left_on='Inspection ID', right_index = True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### -- Merge the inspection and properties information\n",
    "finalDF = pd.merge(finalDF, prop, 'left', left_on='PID_base', \n",
    "                  right_on='GISPROPNUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- check if there are inspected parks that aren't in allsites\n",
    "check_ALLSITES = False\n",
    "if check_ALLSITES:\n",
    "    print(\"checking allsites file...\")\n",
    "    for ii,pid in enumerate(inspection['Prop ID']):\n",
    "        flag = True\n",
    "        for asid in sites['Prop ID']:\n",
    "            if pid==asid:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            print(\"couldn't find {0} : {1}\".format(ii,pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- check features file\n",
    "check_FEATRAT = False\n",
    "if check_FEATRAT:\n",
    "    for ii,iid in enumerate(inspection['Inspection ID']):\n",
    "        if iid not in pivotInspect.index:\n",
    "            print(\"couldn't find {0} : Inspection ID: {1}\".format(ii,iid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- check properties\n",
    "check_PROP = False\n",
    "if check_PROP:\n",
    "    print(\"checking properties file...\")\n",
    "    pid_bad = []\n",
    "    pid_bad_ii = []\n",
    "    for ii,pid in enumerate(inspection['PID_base']):\n",
    "        flag = True\n",
    "        for gpn in prop.GISPROPNUM:\n",
    "            if pid==gpn:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            if pid not in pid_bad:\n",
    "                pid_bad_ii.append(ii)\n",
    "                pid_bad.append(pid)\n",
    "            print(\"couldn't find {0} : {1}\".format(ii,pid))\n",
    "\n",
    "    for ii in range(len(pid_bad_ii)):\n",
    "        subcat = sites.iloc[sites[sites['Prop ID'] == \\\n",
    "                                inspection.iloc[pid_bad_ii[ii]]['Prop ID']] \\\n",
    "                                .index[0]]['Sub-Category']\n",
    "        print(\"{0:8} : {1}\" \\\n",
    "                  .format(inspection.iloc[pid_bad_ii[ii]]['Prop ID'],subcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/share/gdobler/parqa/output/Dataframes/2004_Inspections.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-356d2b63d6c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0myearDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinalDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinalDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mout_year_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_year_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_Inspections.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0myearDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_year_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                                      \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m                                      decimal=decimal)\n\u001b[1;32m-> 1184\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/site-packages/pandas/core/format.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m             f = com._get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m-> 1417\u001b[1;33m                                 encoding=self.encoding)\n\u001b[0m\u001b[0;32m   1418\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/anaconda/root/lib/python2.7/site-packages/pandas/core/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m   2829\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2831\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2833\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/scratch/share/gdobler/parqa/output/Dataframes/2004_Inspections.csv'"
     ]
    }
   ],
   "source": [
    "# -- export Year files\n",
    "#out_year_path = os.path.join('../../parqa/Outputs','Dataframes')\n",
    "out_year_path = os.path.join('/scratch/share/gdobler/parqa/output','Dataframes')\n",
    "inspecYears = sorted(set(map(lambda x: x.year, finalDF['Date'])))\n",
    "\n",
    "for year in inspecYears:\n",
    "    yearDF = finalDF[finalDF['Date'].map(lambda x: x.year) == year].reset_index(drop=True)\n",
    "    out_year_filename = os.path.join(out_year_path, str(year) + '_Inspections.csv')\n",
    "    yearDF.to_csv(out_year_filename, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- test Read\n",
    "#yearDemoDF = pd.DataFrame.from_csv(out_year_filename.replace('15', '08'), sep='\\t')\n",
    "yearDemoDF = finalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- categories\n",
    "categories = [u'Athletic Fields', u'Benches',\n",
    "       u'Fences', u'Glass', u'Graffiti', u'Horticultural Areas', u'Ice',\n",
    "       u'Lawns', u'Litter', u'Paved Surfaces', u'Play Equipment',\n",
    "       u'Safety Surface', u'Sidewalks', u'Trails', u'Trees', u'Water Bodies',\n",
    "       u'Weeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- calculate inspection scores [ratio]\n",
    "yearDemoDF['Ratings Ratio'] = yearDemoDF[categories].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- seed final park stats DF\n",
    "byParkID = yearDemoDF[['Prop ID', 'PID_base', 'Category', 'ZIPCODE']].groupby(['Prop ID'], as_index = False)\n",
    "parkStats = byParkID.first()\n",
    "\n",
    "# -- average Park Score and Acres\n",
    "byParkBase = yearDemoDF.groupby(['PID_base'], as_index = False)\n",
    "parkAvgScore = byParkBase['Ratings Ratio','ACRES_x'].mean()\n",
    "parkAvgScore.rename(columns={'Ratings Ratio':'Avg Ratio'}, inplace=True)\n",
    "parkStats = pd.merge(parkStats, parkAvgScore, on='PID_base', how='left')\n",
    "\n",
    "# -- calculate weighted Score for park\n",
    "parkStats['Weighted Score'] = parkStats['Avg Ratio'] * parkStats['ACRES_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- seed district_category stats DF\n",
    "byCategory = parkStats.groupby(['ZIPCODE', 'Category'], as_index = False)\n",
    "categoryStats = byCategory.first()[['ZIPCODE', 'Category']]\n",
    "\n",
    "# -- sum Acres and Scores per category\n",
    "catSums = byCategory['ACRES_x', 'Weighted Score'].sum()\n",
    "catSums.rename(columns={'Weighted Score':'Score'}, inplace=True)\n",
    "categoryStats = pd.merge(categoryStats, catSums, on=['ZIPCODE', 'Category'], how='left')\n",
    "\n",
    "# -- count parks per category\n",
    "catCounts = byCategory.size().reset_index().rename(columns={0:'Counts'})\n",
    "categoryStats = pd.merge(categoryStats, catCounts, on=['ZIPCODE', 'Category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- group by zipcode and category\n",
    "byZIPCODE = categoryStats.groupby('ZIPCODE', as_index = False)\n",
    "ZIPCODESums = byZIPCODE.sum()[['ZIPCODE', 'Counts']]\n",
    "\n",
    "categoryStats = pd.merge(categoryStats, ZIPCODESums, on='ZIPCODE', how = 'left', suffixes = ['_Cat', '_ZIPCODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- calculate weighted score for zipcode\n",
    "categoryStats['Weighted Score'] = categoryStats['Score'] / categoryStats['ACRES_x']\n",
    "categoryStats['Normalized Score'] = categoryStats['Weighted Score'] * (categoryStats['Counts_Cat'] / categoryStats['Counts_ZIPCODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- sum Scores per Zipcode\n",
    "byZIPCODE = categoryStats.groupby('ZIPCODE')\n",
    "ZIPCODEStats = byZIPCODE \\\n",
    "                    .sum() \\\n",
    "                    .reset_index() \\\n",
    "                    [['ZIPCODE', 'Normalized Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "ZIPCODEStats.to_csv('ParkQualityZipcode.csv', sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
